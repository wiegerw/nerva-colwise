<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.23">
<meta name="description" content="Documentation for the nerva-rowwise repository.">
<meta name="author" content="Wieger Wesselink">
<meta name="copyright" content="Copyright 2024 Wieger Wesselink">
<title>The Nerva-Rowwise Python manual</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child{border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active,#footnotes .footnote a:first-of-type:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<style>
pre.rouge table td { padding: 5px; }
pre.rouge table pre { margin: 0; }
pre.rouge, pre.rouge .w {
  color: #24292f;
  background-color: #f6f8fa;
}
pre.rouge .k, pre.rouge .kd, pre.rouge .kn, pre.rouge .kp, pre.rouge .kr, pre.rouge .kt, pre.rouge .kv {
  color: #cf222e;
}
pre.rouge .gr {
  color: #f6f8fa;
}
pre.rouge .gd {
  color: #82071e;
  background-color: #ffebe9;
}
pre.rouge .nb {
  color: #953800;
}
pre.rouge .nc {
  color: #953800;
}
pre.rouge .no {
  color: #953800;
}
pre.rouge .nn {
  color: #953800;
}
pre.rouge .sr {
  color: #116329;
}
pre.rouge .na {
  color: #116329;
}
pre.rouge .nt {
  color: #116329;
}
pre.rouge .gi {
  color: #116329;
  background-color: #dafbe1;
}
pre.rouge .ges {
  font-weight: bold;
  font-style: italic;
}
pre.rouge .kc {
  color: #0550ae;
}
pre.rouge .l, pre.rouge .ld, pre.rouge .m, pre.rouge .mb, pre.rouge .mf, pre.rouge .mh, pre.rouge .mi, pre.rouge .il, pre.rouge .mo, pre.rouge .mx {
  color: #0550ae;
}
pre.rouge .sb {
  color: #0550ae;
}
pre.rouge .bp {
  color: #0550ae;
}
pre.rouge .ne {
  color: #0550ae;
}
pre.rouge .nl {
  color: #0550ae;
}
pre.rouge .py {
  color: #0550ae;
}
pre.rouge .nv, pre.rouge .vc, pre.rouge .vg, pre.rouge .vi, pre.rouge .vm {
  color: #0550ae;
}
pre.rouge .o, pre.rouge .ow {
  color: #0550ae;
}
pre.rouge .gh {
  color: #0550ae;
  font-weight: bold;
}
pre.rouge .gu {
  color: #0550ae;
  font-weight: bold;
}
pre.rouge .s, pre.rouge .sa, pre.rouge .sc, pre.rouge .dl, pre.rouge .sd, pre.rouge .s2, pre.rouge .se, pre.rouge .sh, pre.rouge .sx, pre.rouge .s1, pre.rouge .ss {
  color: #0a3069;
}
pre.rouge .nd {
  color: #8250df;
}
pre.rouge .nf, pre.rouge .fm {
  color: #8250df;
}
pre.rouge .err {
  color: #f6f8fa;
  background-color: #82071e;
}
pre.rouge .c, pre.rouge .ch, pre.rouge .cd, pre.rouge .cm, pre.rouge .cp, pre.rouge .cpf, pre.rouge .c1, pre.rouge .cs {
  color: #6e7781;
}
pre.rouge .gl {
  color: #6e7781;
}
pre.rouge .gt {
  color: #6e7781;
}
pre.rouge .ni {
  color: #24292f;
}
pre.rouge .si {
  color: #24292f;
}
pre.rouge .ge {
  color: #24292f;
  font-style: italic;
}
pre.rouge .gs {
  color: #24292f;
  font-weight: bold;
}
</style>
</head>
<body id="demo" class="book toc2 toc-left">
<div id="header">
<h1>The Nerva-Rowwise Python manual</h1>
<div class="details">
<span id="author" class="author">Wieger Wesselink</span><br>
<span id="email" class="email"><a href="mailto:j.w.wesselink@tue.nl">j.w.wesselink@tue.nl</a></span><br>
</div>
<div id="toc" class="toc2">
<div id="toctitle"><h3>Contents</h3></div>
<ul class="sectlevel1">
<li><a href="#_introduction">Introduction</a></li>
<li><a href="#_installation">Installation</a>
<ul class="sectlevel2">
<li><a href="#_dependencies">Dependencies</a></li>
</ul>
</li>
<li><a href="#_command_line_tools">Command line tools</a>
<ul class="sectlevel2">
<li><a href="#_the_tool_mlp_py">The tool mlp.py</a></li>
</ul>
</li>
<li><a href="#_overview_of_the_code">Overview of the code</a>
<ul class="sectlevel2">
<li><a href="#_number_type">Number type</a></li>
<li><a href="#_module_contents">Module contents</a></li>
<li><a href="#_classes">Classes</a></li>
<li><a href="#_accessing_c_data_structures">Accessing C++ data structures</a></li>
<li><a href="#_training_a_neural_network">Training a neural network</a></li>
</ul>
</li>
<li><a href="#io">I/O</a></li>
<li><a href="#_extending_the_library">Extending the library</a>
<ul class="sectlevel2">
<li><a href="#_adding_a_loss_function">Adding a loss function</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<style>
  .small-code .content pre {
      font-size: 0.7em;
  }
</style>
</div>
</div>
<div class="sect1">
<h2 id="_introduction">Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This document describes the implementation of the <em>Nerva-Rowwise Python Library</em>. This library features a Python module named <code>nerva</code>, that is built using Python bindings to the
<a href="https://wiegerw.github.io/nerva-rowwise/doc/nerva-cpp.html">Nerva-Rowwise C++ Library</a>. Note that the matrix type used internally in the <code>nerva</code> module is <code>torch.Tensor</code>, to ensure an easy integration with PyTorch.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_installation">Installation</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The <em>Nerva-Rowwise Python Library</em> Python bindings can be installed via <code>pip</code>. The installation is done via a <a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/setup.py">setup.py</a> script. The script has several dependencies, that need to be resolved using environment variables.</p>
</div>
<div class="sect2">
<h3 id="_dependencies">Dependencies</h3>
<div class="ulist">
<ul>
<li>
<p>Intel MKL library <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html">oneMKL</a></p>
</li>
<li>
<p>FMT <a href="https://github.com/fmtlib/fmt" class="bare">https://github.com/fmtlib/fmt</a></p>
</li>
<li>
<p>Eigen <a href="https://eigen.tuxfamily.org/" class="bare">https://eigen.tuxfamily.org/</a></p>
</li>
<li>
<p>pybind11 <a href="https://github.com/pybind/pybind11" class="bare">https://github.com/pybind/pybind11</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>The MKL dependency can be resolved by setting the <code>MKL_ROOT</code> environment variable, or by setting the <code>ONEAPI_ROOT</code> environment variable.</p>
</div>
<div class="paragraph">
<p>To resolve the FMT, Eigen and pybind11 dependencies, the environment variables
<code>EIGEN_INCLUDE_DIR</code>, <code>FMT_INCLUDE_DIR</code> and <code>PYBIND11_INCLUDE_DIR</code> can be set.</p>
</div>
<div class="paragraph">
<p>An alternative solution is to use CMake to resolve these three dependencies, see also the
<a href="nerva-cpp.adoc#cmake-build">CMake install</a> section in the C++ documentation. The <code>cmake</code> command causes the three libraries to be downloaded automatically in the <code>_deps</code> subdirectory of the CMake build directory. After that it is sufficient to set the environment variable <code>CMAKE_DEPS_DIR</code>.</p>
</div>
<div id="pip-install" class="paragraph">
<p>The <code>nerva</code> Python module can then be installed using</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code>cd python
pip install .</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_command_line_tools">Command line tools</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The tool <code>mlp.py</code> can be used to do training experiments with multilayer perceptrons.</p>
</div>
<div class="sect2">
<h3 id="_the_tool_mlp_py">The tool mlp.py</h3>
<div class="paragraph">
<p>An example invocation of the <code>mlp.py</code> tool is</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="rouge highlight"><code>python ../python/tools/mlp.py \
    --layers="ReLU;ReLU;Linear" \
    --layer-sizes="3072;1024;1024;10" \
    --layer-weights=Xavier \
    --optimizers="Nesterov(0.9)" \
    --loss=SoftmaxCrossEntropy \
    --learning-rate=0.01 \
    --epochs=100 \
    --batch-size=100 \
    --threads=12 \
    --overall-density=0.05 \
    --cifar10=../data \
    --seed=123</code></pre>
</div>
</div>
<div class="paragraph">
<p>This will train a CIFAR-10 model using an MLP consisting of three layers with activation functions ReLU, ReLU and no activation. Note that it automatically downloads the CIFAR-10 dataset in the folder <code>../data</code> if it doesn&#8217;t yet exist.</p>
</div>
<div class="paragraph">
<p>The output may look like this:</p>
</div>
<div class="listingblock small-code">
<div class="content">
<pre class="rouge highlight"><code>=== Nerva python model ===
Sequential(
  Sparse(output_size=1024, density=0.042382812500000006, activation=ReLU(), optimizer=Nesterov(0.9), weight_initializer=Xavier),
  Sparse(output_size=1024, density=0.06357421875000001, activation=ReLU(), optimizer=Nesterov(0.9), weight_initializer=Xavier),
  Dense(output_size=10, activation=NoActivation(), optimizer=Nesterov(0.9), weight_initializer=Xavier, dropout=0.0)
)
loss = SoftmaxCrossEntropyLoss()
scheduler = ConstantScheduler(lr=0.009999999776482582)
layer densities: 133325/3145728 (4.238%), 66662/1048576 (6.357%), 10240/10240 (100%)


=== Training Nerva model ===
epoch   0  lr: 0.01000000  loss: 2.30246344  train accuracy: 0.10724000  test accuracy: 0.11390000  time: 0.00000000s
epoch   1  lr: 0.01000000  loss: 1.89570341  train accuracy: 0.32142000  test accuracy: 0.32030000  time: 4.15395873s
epoch   2  lr: 0.01000000  loss: 1.66956488  train accuracy: 0.40332000  test accuracy: 0.40220000  time: 3.60670412s
epoch   3  lr: 0.01000000  loss: 1.53549386  train accuracy: 0.45616000  test accuracy: 0.44940000  time: 3.24853144s
epoch   4  lr: 0.01000000  loss: 1.43913857  train accuracy: 0.49054000  test accuracy: 0.47920000  time: 3.29059404s
epoch   5  lr: 0.01000000  loss: 1.36875251  train accuracy: 0.51380000  test accuracy: 0.49070000  time: 3.83244992s
epoch   6  lr: 0.01000000  loss: 1.29761993  train accuracy: 0.54106000  test accuracy: 0.50710000  time: 3.59350869s
epoch   7  lr: 0.01000000  loss: 1.23931273  train accuracy: 0.56170000  test accuracy: 0.51690000  time: 3.96624650s</code></pre>
</div>
</div>
<div class="sect3">
<h4 id="mlp_tool">mlp.py command line options</h4>
<div class="paragraph">
<p>This section gives an overview of the command line interface of the <code>mlp.py</code> tool.</p>
</div>
<div class="sect4">
<h5 id="_parameters_lists">Parameters lists</h5>
<div class="paragraph">
<p>Some command line options take a list of items as input, for example a list of layers. These items must be separated by semicolons, e.g. <code>--layers="ReLU;ReLU;Linear"</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_named_parameters">Named parameters</h5>
<div class="paragraph">
<p>Some of the items take parameters. For this we use a function call syntax with named parameters, e.g. <code>AllReLU(alpha=0.3)</code>. In case that there is only one parameter, the name may be omitted: <code>AllReLU(0.3)</code>. If the parameters have default values, they may be omitted. For example, <code>TReLU</code> or <code>TReLU()</code> is equivalent to <code>TReLU(al=0,tl=0,ar=0,tr=1)</code>.</p>
</div>
</div>
<div class="sect4">
<h5 id="_general_options">General options</h5>
<div class="ulist">
<ul>
<li>
<p><code>-?</code>, <code>-h</code>, <code>--help</code>
Display help information.</p>
</li>
<li>
<p><code>--debug</code>, <code>-d</code>
Show debug output. This prints batches, weight matrices, bias vectors, gradients etc.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_random_generator_options">Random generator options</h5>
<div class="ulist">
<ul>
<li>
<p><code>--seed &lt;value&gt;</code>
A seed value for the random generator.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_layer_configuration_options">Layer configuration options</h5>
<div class="ulist">
<ul>
<li>
<p><code>--layers &lt;value&gt;</code>
A semicolon separated list of layers. For example, <code>--layers=ReLU;AllReLU(0.3);Linear</code> is used to specify a neural network with three layers with an ReLU, AllReLU and no activation function. The following layers are supported:</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Specification</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Linear</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linear layer without activation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>ReLU</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linear layer with ReLU activation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Sigmoid</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linear layer with sigmoid activation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Softmax</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linear layer with softmax activation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>LogSoftmax</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linear layer with log-softmax activation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>HyperbolicTangent</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linear layer with hyperbolic tangent activation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>AllReLU(&lt;alpha&gt;)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linear layer with All ReLU activation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>SReLU(&lt;al&gt;,&lt;tl&gt;,&lt;ar&gt;,&lt;tr&gt;)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linear layer with SReLU activation. The default value for the parameters are <code>al=0, tl=0, ar=0, tr=1</code>. For these
 values <code>SReLU</code> coincides with <code>ReLU</code>.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>TReLU(&lt;epsilon&gt;)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Linear layer with trimmed ReLU activation</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>BatchNormalization</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Batch normalization layer</p></td>
</tr>
</tbody>
</table>
<div class="ulist">
<ul>
<li>
<p><code>--layer-sizes &lt;value&gt;</code>
A semicolon-separated list of the sizes of linear layers of the multilayer perceptron. For example, <code>--layer-sizes=3072;1024;512;10</code> specifies the sizes of three linear layers. The first one has 3072 inputs and 1024 outputs, the second one 1024 inputs and 512 outputs, and the third one has 512 inputs and 10 outputs.</p>
</li>
<li>
<p><code>--densities &lt;value&gt;</code>
A comma-separated list of linear layer densities. By default, all linear layers are dense (i.e. have density 1.0). If only one value is
 specified, it will be used for all linear layers.</p>
</li>
<li>
<p><code>--dropouts &lt;value&gt;</code>
A comma-separated list of dropout rates of linear layers. By default, all linear layers have no dropout (i.e. dropout rate 0.0).</p>
</li>
<li>
<p><code>--overall-density &lt;value&gt;</code>
The overall density of the linear layers. This value should be in the interval \([0,1\)], and it specifies the fraction of the total number of weights that is non-zero. The overall density is not distributed evenly over the layers. Instead, small layers will be assigned a higher density than large layers.</p>
</li>
<li>
<p><code>--layer-weights &lt;value&gt;</code>
The generator that is used for initializing the weights of the linear layers. The following weight generators are supported:</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Specification</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Xavier</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Xavier weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>XavierNormalized</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Normalized Xavier weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>He</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Kaiming He weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Uniform</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Uniform weights</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Zero</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">All weights are zero (N.B. This usually doesn&#8217;t work)</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect4">
<h5 id="_training_configuration_options">Training configuration options</h5>
<div class="ulist">
<ul>
<li>
<p><code>--epochs &lt;value&gt;</code>
The number of epochs of the training (default: 100).</p>
</li>
<li>
<p><code>--batch-size &lt;value&gt;</code>
The batch size of the training.</p>
</li>
<li>
<p><code>--no-shuffle</code>
Do not shuffle the dataset during training.</p>
</li>
<li>
<p><code>--no-statistics</code>
Do not display intermediate statistics during training.</p>
</li>
<li>
<p><code>--optimizers &lt;value&gt;</code>
A semicolon-separated list of optimizers used for linear and batch normalization layers. The following optimizers are supported:</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Specification</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>GradientDescent</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Gradient descent optimization</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Momentum(mu)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Momentum optimization with momentum parameter <code>mu</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Nesterov(mu)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nesterov optimization with momentum parameter <code>mu</code></p></td>
</tr>
</tbody>
</table>
<div class="ulist">
<ul>
<li>
<p><code>--learning-rate &lt;value&gt;</code>
A semicolon-separated list of learning rate schedulers of linear and batch normalization layers. If only one learning rate scheduler is specified, it is applied to all layers. The following learning rate schedulers are supported:</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Specification</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Constant(lr)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Constant learning rate <code>lr</code></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>TimeBased(lr, decay)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Adaptive learning rate with decay</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>StepBased(lr, drop_rate, change_rate)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Step based learning rate where the learning rate is regularly dropped
to a lower value</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>MultistepLR(lr, milestones, gamma)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Step based learning rate, where <code>milestones</code> contains the epoch numbers in which the learning rate is dropped.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Exponential(lr, change_rate)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Exponentially decreasing learning rate</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>See also <a href="https://en.wikipedia.org/wiki/Learning_rate" class="bare">https://en.wikipedia.org/wiki/Learning_rate</a>.</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>--loss &lt;value&gt;</code>
The loss function used for training the multilayer perceptron. The following loss functions are supported:</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Specification</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>SquaredError</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Squared error loss.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>CrossEntropy</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cross entropy loss (N.B. prone to numerical problems!)</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>LogisticCrossEntropy</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Logistic cross entropy loss.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>SoftmaxCrossEntropy</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Softmax cross entropy loss. Matches <code>CrossEntropy</code> of PyTorch. Suitable for classification experiments.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>NegativeLogLikelihood</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Negative log likelihood loss.</p></td>
</tr>
</tbody>
</table>
<div class="ulist">
<ul>
<li>
<p><code>--load-weights &lt;value&gt;</code>
Load weights and biases from a dictionary in NumPy <code>.npz</code> format.
The weight matrices should be stored with keys <code>W1,W2,&#8230;&#8203;</code> and the bias vectors with keys <code>b1,b2,&#8230;&#8203;</code>.
See also
<a href="https://numpy.org/doc/stable/reference/generated/numpy.lib.format.html">numpy.lib.format</a>.</p>
</li>
<li>
<p><code>--save-weights &lt;value&gt;</code>
Save weights and biases to a dictionary in NumPy <code>.npz</code> format.
The weight matrices are stored with keys <code>W1,W2,&#8230;&#8203;</code> and the bias vectors with keys <code>b1,b2,&#8230;&#8203;</code>.
See also
<a href="https://numpy.org/doc/stable/reference/generated/numpy.lib.format.html">numpy.lib.format</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_pruning_and_growing_options">Pruning and growing options</h5>
<div class="ulist">
<ul>
<li>
<p><code>--prune &lt;strategy&gt;</code>
The strategy used for pruning sparse weight matrices. The following strategies are supported:</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Specification</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Magnitude(&lt;drop_fraction&gt;)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Magnitude based pruning. A fraction of the weights with the smallest absolute value is pruned.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>SET(&lt;drop_fraction&gt;)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">SET pruning. Positive and negative weights are treated separately. Both a fraction of the positive and a fraction of the negative weights is pruned.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Threshold(&lt;threshold&gt;)</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weights with absolute value below the given threshold are pruned.</p></td>
</tr>
</tbody>
</table>
<div class="ulist">
<ul>
<li>
<p><code>--grow &lt;strategy&gt;</code>
The strategy used for growing in sparse weight matrices. The following strategies are supported:</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Specification</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Random</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weights are added at random positions (outside the support of the sparse matrix).</p></td>
</tr>
</tbody>
</table>
<div class="ulist">
<ul>
<li>
<p><code>--grow-weights &lt;value&gt;</code>
The weight generation function used for growing weights.
See <code>--layer-weights</code> for supported values. The default value is <code>Xavier</code>.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_computation_options">Computation options</h5>
<div class="ulist">
<ul>
<li>
<p><code>--computation &lt;value&gt;</code>
The computation mode that is used for backpropagation. This is used for performance measurements. The following computation modes are available:</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Specification</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>eigen</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">All computations are done using the Eigen library. Note that by setting the flag <code>EIGEN_USE_MKL_ALL</code> Eigen will attempt to use MKL library calls.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>mkl</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Some computations are implemented using MKL functions.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>blas</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Some computations are implemented using BLAS functions.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>sycl</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Some computations are implemented using SYCL functions.</p></td>
</tr>
</tbody>
</table>
<div class="ulist">
<ul>
<li>
<p><code>--clip &lt;value&gt;</code>
A threshold value used to set small elements of weight matrices to zero.</p>
</li>
<li>
<p><code>--threads &lt;value&gt;</code>
The number of threads used by the MKL and OMP libraries.</p>
</li>
<li>
<p><code>--gradient-step &lt;value&gt;</code>
If this value is set, gradient checks are performed with the given step size. This is very slow, and should only be used for debugging.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_dataset_options">Dataset options</h5>
<div class="ulist">
<ul>
<li>
<p><code>--cifar10 &lt;directory&gt;</code>
Specify the directory where the binary version of the
<a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a> dataset is stored. This is a directory with subdirectory <code>cifar-10-batches-bin</code> for the C++ version or <code>cifar-10-batches-py</code> for the Python version of the dataset.</p>
</li>
<li>
<p><code>--mnist &lt;directory&gt;</code>
Specify the directory where the <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a> dataset is stored.
It should be stored in a file named <code>mnist.npz</code>, that can be downloaded <a href="https://s3.amazonaws.com/img-datasets/mnist.npz">here</a>.</p>
</li>
<li>
<p><code>--load-data &lt;value&gt;</code>
Load the dataset from a file in NumPy <code>.npz</code> format. See</p>
</li>
<li>
<p><code>--save-data &lt;value&gt;</code>
Save the dataset to a file in NumPy <code>.npz</code> format. See</p>
</li>
<li>
<p><code>--normalize</code>
Normalize the dataset.</p>
</li>
<li>
<p><code>--preprocessed &lt;directory&gt;</code>
A directory containing datasets named <code>epoch0.npz</code>, <code>epoch1.npz</code>, &#8230;&#8203; See <a href="#io">I/O</a> for information about the <code>.npz</code> format. This can for example be used to precompute augmented datasets. A script <a href="../python/tools/generate_cifar10_augmented_datasets.py">generate_cifar10_augmented_datasets.py</a> is available for creating augmented CIFAR-10 datasets.</p>
</li>
</ul>
</div>
</div>
<div class="sect4">
<h5 id="_miscellaneous_options">Miscellaneous options</h5>
<div class="ulist">
<ul>
<li>
<p><code>--info</code>
Print detailed information about the multilayer perceptron.</p>
</li>
<li>
<p><code>--timer</code>
Print timer messages. The following values are supported:</p>
</li>
</ul>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Value</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>disabled</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">No timing information is displayed</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>brief</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">At the end, a report with accumulated timing measurements will be displayed</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>full</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">In addition, individual timing measurements will be displayed</p></td>
</tr>
</tbody>
</table>
<div class="ulist">
<ul>
<li>
<p><code>--precision &lt;value&gt;</code>
The precision used for printing matrix elements.</p>
</li>
<li>
<p><code>--edgeitems &lt;value&gt;</code>
The edgeitems used for printing matrices. This sets the number of border rows and columns that are printed.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_overview_of_the_code">Overview of the code</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This section gives an overview of the Python code in the
<em>Nerva-Rowwise Python Library</em>, and some explanations about the code.</p>
</div>
<div class="sect2">
<h3 id="_number_type">Number type</h3>
<div class="paragraph">
<p>The <em>Nerva-Rowwise Python Library</em> uses 32-bit floats as its number type. The C++ library also supports 64-bit floats.</p>
</div>
</div>
<div class="sect2">
<h3 id="_module_contents">Module contents</h3>
<div class="paragraph">
<p>The most important files in the <code>nerva</code> module are given in the table below.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">File</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/nerva/multilayer_perceptron.py">multilayer_perceptron.py</a></code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A multilayer perceptron class.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/nerva/layers.py">layers.py</a></code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Neural network layers.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/nerva/activation_functions.py">activation_functions.py</a></code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Activation functions.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/nerva/loss_functions.py">loss_functions.py</a></code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Loss functions.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/nerva/weights.py">weights.py</a></code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Weight initialization functions.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/nerva/optimizers.py">optimizers.py</a></code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Optimizer functions, for updating neural network parameters using their gradients.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/nerva/learning_rate_schedulers.py">learning_rate_schedulers.py</a></code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Learning rate schedulers, for updating the learning rate during training.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/nerva/training.py">training.py</a></code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A stochastic gradient descent algorithm.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/nerva/prune.py">prune.py</a></code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Algorithms for pruning sparse weight matrices. This is used for dynamic sparse training.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/nerva/grow.py">grow.py</a></code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Algorithms for (re-)growing sparse weights. This is used for dynamic sparse training.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect2">
<h3 id="_classes">Classes</h3>
<div class="sect3">
<h4 id="_class_multilayerperceptron">Class MultilayerPerceptron</h4>
<div class="paragraph">
<p>A multilayer perceptron (MLP) is modeled using the class <code>MultilayerPerceptron</code>. It contains a list of layers, and has member functions <code>feedforward</code>, <code>backpropagate</code> and <code>optimize</code> that can be used for training the neural network. Constructing an MLP can be done as follows:</p>
</div>
<div id="construct_mlp1" class="listingblock small-code">
<div class="content">
<pre class="rouge highlight"><code data-lang="cpp"><span class="n">def</span> <span class="n">construct_mlp1</span><span class="p">(</span><span class="n">sizes</span><span class="o">:</span> <span class="n">List</span><span class="p">[</span><span class="kt">int</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">:</span> <span class="kt">int</span><span class="p">)</span><span class="o">:</span>

    <span class="n">layer1</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                   <span class="n">output_size</span><span class="o">=</span><span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                   <span class="n">activation</span><span class="o">=</span><span class="n">ReLU</span><span class="p">(),</span>
                   <span class="n">optimizer</span><span class="o">=</span><span class="n">GradientDescent</span><span class="p">(),</span>
                   <span class="n">weight_initializer</span><span class="o">=</span><span class="n">Xavier</span><span class="p">())</span>

    <span class="n">layer2</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                   <span class="n">output_size</span><span class="o">=</span><span class="n">sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                   <span class="n">activation</span><span class="o">=</span><span class="n">ReLU</span><span class="p">(),</span>
                   <span class="n">optimizer</span><span class="o">=</span><span class="n">GradientDescent</span><span class="p">(),</span>
                   <span class="n">weight_initializer</span><span class="o">=</span><span class="n">Xavier</span><span class="p">())</span>

    <span class="n">layer3</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                   <span class="n">output_size</span><span class="o">=</span><span class="n">sizes</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                   <span class="n">activation</span><span class="o">=</span><span class="n">NoActivation</span><span class="p">(),</span>
                   <span class="n">optimizer</span><span class="o">=</span><span class="n">GradientDescent</span><span class="p">(),</span>
                   <span class="n">weight_initializer</span><span class="o">=</span><span class="n">Xavier</span><span class="p">())</span>

    <span class="n">M</span> <span class="o">=</span> <span class="n">MultilayerPerceptron</span><span class="p">()</span>
    <span class="n">M</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer1</span><span class="p">,</span> <span class="n">layer2</span><span class="p">,</span> <span class="n">layer3</span><span class="p">]</span>
    <span class="n">M</span><span class="p">.</span><span class="n">compile</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>  <span class="err">#</span> <span class="n">Initialize</span> <span class="n">the</span> <span class="n">C</span><span class="o">++</span> <span class="n">data</span> <span class="n">structures</span>

    <span class="k">return</span> <span class="n">M</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This creates an MLP with three linear layers. The parameter <code>sizes</code> contains the input and output sizes of the three layers. The weights are initialized using Xavier.</p>
</div>
<div class="paragraph">
<p>Another way to construct MLPs is provided by the function <code>make_layers</code>, that offers a string based interface. An example is given in the code below:</p>
</div>
<div id="construct_mlp2" class="listingblock small-code">
<div class="content">
<pre class="rouge highlight"><code data-lang="cpp"><span class="n">def</span> <span class="n">construct_mlp2</span><span class="p">(</span><span class="n">linear_layer_sizes</span><span class="o">:</span> <span class="n">List</span><span class="p">[</span><span class="kt">int</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">:</span> <span class="kt">int</span><span class="p">)</span><span class="o">:</span>

    <span class="n">layer_specifications</span> <span class="o">=</span> <span class="p">[</span><span class="s">"ReLU"</span><span class="p">,</span> <span class="s">"ReLU"</span><span class="p">,</span> <span class="s">"Linear"</span><span class="p">]</span>
    <span class="n">linear_layer_densities</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]</span>
    <span class="n">linear_layer_dropouts</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
    <span class="n">linear_layer_weights</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Xavier"</span><span class="p">,</span> <span class="s">"Xavier"</span><span class="p">,</span> <span class="s">"Xavier"</span><span class="p">]</span>
    <span class="n">layer_optimizers</span> <span class="o">=</span> <span class="p">[</span><span class="s">"GradientDescent"</span><span class="p">,</span> <span class="s">"GradientDescent"</span><span class="p">,</span> <span class="s">"GradientDescent"</span><span class="p">]</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="n">make_layers</span><span class="p">(</span><span class="n">layer_specifications</span><span class="p">,</span>
                         <span class="n">linear_layer_sizes</span><span class="p">,</span>
                         <span class="n">linear_layer_densities</span><span class="p">,</span>
                         <span class="n">linear_layer_dropouts</span><span class="p">,</span>
                         <span class="n">linear_layer_weights</span><span class="p">,</span>
                         <span class="n">layer_optimizers</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">MultilayerPerceptron</span><span class="p">()</span>
    <span class="n">M</span><span class="p">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">layers</span>
    <span class="n">M</span><span class="p">.</span><span class="n">compile</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>  <span class="err">#</span> <span class="n">Initialize</span> <span class="n">the</span> <span class="n">C</span><span class="o">++</span> <span class="n">data</span> <span class="n">structures</span>

    <span class="k">return</span> <span class="n">M</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Note that optimizers should be specified for linear layers, but also for batch normalization layers.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A <code>MultilayerPerceptron</code> needs to be compiled before it can be used. This is done by calling <code>M.compile(batch_size)</code>. As a result of this call, a C++ object is created that contains the actual model. A reference to this object is stored in the attribute <code>_model</code>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect3">
<h4 id="_class_layer">Class Layer</h4>
<div class="paragraph">
<p>The class <code>Layer</code> is the base class of all neural network layers. There are three different types of layers:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Layer</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Dense</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A dense linear layer.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>Sparse</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A sparse linear layer.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>BatchNormalization</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A batch normalization layer.</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>A <code>Dense</code> layer has a constructor with the following parameters:</p>
</div>
<div class="listingblock small-code">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><span class="n">Unresolved</span> <span class="n">directive</span> <span class="ow">in</span> <span class="n">nerva</span><span class="o">-</span><span class="n">python</span><span class="p">.</span><span class="n">adoc</span> <span class="o">-</span> <span class="n">include</span><span class="p">::..</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">nerva</span><span class="o">/</span><span class="n">layers</span><span class="p">.</span><span class="n">py</span><span class="p">[</span><span class="n">tag</span><span class="o">=</span><span class="n">dense_constructor</span><span class="p">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>This only sets a number of attributes of the layer. Before using the layer the <code>compile</code> function must be called:</p>
</div>
<div class="listingblock small-code">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><span class="n">Unresolved</span> <span class="n">directive</span> <span class="ow">in</span> <span class="n">nerva</span><span class="o">-</span><span class="n">python</span><span class="p">.</span><span class="n">adoc</span> <span class="o">-</span> <span class="n">include</span><span class="p">::..</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">nerva</span><span class="o">/</span><span class="n">layers</span><span class="p">.</span><span class="n">py</span><span class="p">[</span><span class="n">tag</span><span class="o">=</span><span class="n">dense_compile</span><span class="p">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>As a result of this call a C++ object is created that contains the actual layer. It is stored in the attribute <code>_layer</code>. The normal workflow is to call the <code>compile</code> method of the multilayer perceptron, which will also compile the layers, as illustrated in
<a href="#construct_mlp1">[construct_mlp1]</a> and <a href="#construct_mlp2">[construct_mlp2]</a>.</p>
</div>
<div class="paragraph">
<p>A <code>Sparse</code> layer has an additional parameter <code>density</code> in the interval \([0,1]\), that determines the fraction of weights that are in the support. Sparse layers do not support dropout.</p>
</div>
<div class="paragraph">
<p>A <code>BatchNormalization</code> layer has the following constructor:</p>
</div>
<div class="listingblock small-code">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><span class="n">Unresolved</span> <span class="n">directive</span> <span class="ow">in</span> <span class="n">nerva</span><span class="o">-</span><span class="n">python</span><span class="p">.</span><span class="n">adoc</span> <span class="o">-</span> <span class="n">include</span><span class="p">::..</span><span class="o">/</span><span class="n">python</span><span class="o">/</span><span class="n">nerva</span><span class="o">/</span><span class="n">layers</span><span class="p">.</span><span class="n">py</span><span class="p">[</span><span class="n">tag</span><span class="o">=</span><span class="n">batchnormalization_constructor</span><span class="p">]</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The output size may be omitted, since by definition it is the same as the input size.</p>
</div>
</div>
<div class="sect3">
<h4 id="_class_lossfunction">Class LossFunction</h4>
<div class="paragraph">
<p>The class <code>LossFunction</code> is the base class of all loss functions. There are five loss functions available:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>SquaredErrorLoss</code></p>
</li>
<li>
<p><code>CrossEntropyLoss</code></p>
</li>
<li>
<p><code>LogisticCrossEntropyLoss</code></p>
</li>
<li>
<p><code>NegativeLogLikelihoodLoss</code></p>
</li>
<li>
<p><code>SoftmaxCrossEntropyLoss</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>See the <a href="https://wiegerw.github.io/nerva-rowwise/pdf/nerva-library-specifications.pdf">Nerva library specifications</a> document for precise definitions of these loss functions.</p>
</div>
</div>
<div class="sect3">
<h4 id="_activation_functions">Activation functions</h4>
<div class="paragraph">
<p>The class <code>ActivationFunction</code> is the base class of all activation functions. The following activation functions are available:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>ReLU</code></p>
</li>
<li>
<p><code>Sigmoid</code></p>
</li>
<li>
<p><code>Softmax</code></p>
</li>
<li>
<p><code>LogSoftmax</code></p>
</li>
<li>
<p><code>TReLU</code></p>
</li>
<li>
<p><code>LeakyReLU</code></p>
</li>
<li>
<p><code>AllReLU</code></p>
</li>
<li>
<p><code>SReLU</code></p>
</li>
<li>
<p><code>HyperbolicTangent</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>See the <a href="https://wiegerw.github.io/nerva-rowwise/pdf/nerva-library-specifications.pdf">Nerva library specifications</a> document for precise definitions of these activation functions.</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_accessing_c_data_structures">Accessing C++ data structures</h3>
<div class="paragraph">
<p>To a limited extent, the C++ data structures can be accessed in Python. In the file
<code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/tests/loss_test.py">loss_test.py</a></code> it is demonstrated how to modify the weight matrices and bias vectors of dense layers via the <code>_layer</code> attribute:</p>
</div>
<div class="listingblock small-code">
<div class="content">
<pre class="rouge highlight"><code data-lang="python">        <span class="n">M</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">_layer</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W1</span>
        <span class="n">M</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">_layer</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b1</span>
        <span class="n">M</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">_layer</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W2</span>
        <span class="n">M</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">_layer</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b2</span>
        <span class="n">M</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">_layer</span><span class="p">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W3</span>
        <span class="n">M</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">2</span><span class="p">].</span><span class="n">_layer</span><span class="p">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">b3</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>The weight matrices of sparse layers are not yet fully exposed to Python.</p>
</div>
</div>
<div class="sect2">
<h3 id="_training_a_neural_network">Training a neural network</h3>
<div class="paragraph">
<p>The class <code>StochasticGradientDescentAlgorithm</code> can be used to train a neural network. It takes as input a multilayer perceptron, a dataset, a loss function, a learning rate scheduler, and a struct containing options like the number of epochs. The main loop looks like this:</p>
</div>
<div class="listingblock small-code">
<div class="content">
<pre class="rouge highlight"><code data-lang="python"><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">options</span><span class="p">.</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">self</span><span class="p">.</span><span class="nf">on_start_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">batch_index</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train_loader</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">on_start_batch</span><span class="p">(</span><span class="n">batch_index</span><span class="p">)</span>
        <span class="n">T</span> <span class="o">=</span> <span class="nf">to_one_hot</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">M</span><span class="p">.</span><span class="nf">feedforward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">DY</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">loss</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="n">options</span><span class="p">.</span><span class="n">batch_size</span>
        <span class="n">M</span><span class="p">.</span><span class="nf">backpropagate</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">DY</span><span class="p">)</span>
        <span class="n">M</span><span class="p">.</span><span class="nf">optimize</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="nf">on_end_batch</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="nf">on_end_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

<span class="n">self</span><span class="p">.</span><span class="nf">on_end_training</span><span class="p">()</span></code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
We follow the PyTorch convention that the targets used for classification are provided as a one dimensional vector of integers. Using a call to <code>to_one_hot</code> this vector is transformed in to a one hot encoded boolean matrix of the same dimensions as the output <code>Y</code>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In every epoch, the dataset is divided into a number of batches. This is handled by the <code>DataLoader</code>, that creates batches <code>X</code> of a given batch size, with corresponding targets <code>T</code> (i.e. the expected outputs). Each batch goes through the three steps of stochastic gradient descent:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>feedforward:</strong> Given an input batch <code>X</code> and
the neural network parameters <code></code>, compute the
output <code>Y</code>.</p>
</li>
<li>
<p><strong>backpropagation:</strong> Given output <code>Y</code> corresponding to input <code>X</code> and targets <code>T</code>, compute the gradient  <code>DY</code> of <code>Y</code> with respect to the loss function. Then from <code>Y</code> and <code>DY</code>, compute the gradient <code>D</code> of the parameters <code></code>.</p>
</li>
<li>
<p><strong>optimization:</strong> Given the gradient <code>D</code>, update
the parameters <code></code>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Note that the algorithm uses a number of event functions:</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Event</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>on_start_training</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Is called at the start of the training</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>on_end_training</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Is called at the end of the training</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>on_start_epoch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Is called at the start of each epoch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>on_end_epoch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Is called at the end of each epoch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>on_start_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Is called at the start of each batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>on_end_batch</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Is called at the end of each batch</p></td>
</tr>
</tbody>
</table>
<div class="paragraph">
<p>The user can respond to these events by deriving from the class <code>StochasticGgradientDescentAlgorithm</code>. Typical use cases for these event functions are the following:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Update the learning rate.</p>
</li>
<li>
<p>Renew dropout masks.</p>
</li>
<li>
<p>Prune and grow sparse weights.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Such operations are typically done after each epoch or after a given number of batches.</p>
</div>
<div id="on_start_epoch" class="paragraph">
<p>An example can be found in the tool <code>mlp</code>:</p>
</div>
<div class="listingblock small-code">
<div class="content">
<pre class="rouge highlight"><code data-lang="python">    <span class="k">def</span> <span class="nf">on_start_epoch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">self</span><span class="p">.</span><span class="n">reload_data_directory</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="nf">reload_data</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">lr_scheduler</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">lr_scheduler</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">M</span><span class="p">.</span><span class="nf">renew_dropout_masks</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">self</span><span class="p">.</span><span class="n">regrow</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="nf">regrow</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">M</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">self</span><span class="p">.</span><span class="n">clip</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">self</span><span class="p">.</span><span class="n">M</span><span class="p">.</span><span class="n">_model</span><span class="p">.</span><span class="nf">clip</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">clip</span><span class="p">)</span></code></pre>
</div>
</div>
<div class="paragraph">
<p>Five actions take place at the start of every epoch:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A preprocessed dataset is loaded from disk, which is done to avoid the expensive computation of augmented data at every epoch.</p>
</li>
<li>
<p>The learning rate is updated if a learning rate scheduler is set.</p>
</li>
<li>
<p>Dropout masks are renewed.</p>
</li>
<li>
<p>Sparse weight matrices are pruned and regrown if a regrow function is specified.</p>
</li>
<li>
<p>Small weights in the subnormal range are clipped to zero if the <code>clip</code> option is set.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="io">I/O</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The default storage format used in the Nerva libraries is the NumPy NPZ format, see <a href="https://numpy.org/doc/stable/reference/generated/numpy.lib.format.html">numpy.lib.format</a>. The reason for choosing this format is portability between C++ and Python implementations. A file in <code>.npz</code> format can be used to store a dictionary of arrays.</p>
</div>
<div class="paragraph">
<p>The <code>mlp.py</code> tool has options <code>--load-weights</code> and <code>--save-weights</code> for loading and saving the weights and bias vectors of an MLP, and options <code>--load-data</code> and <code>--save-data</code> for loading and saving a dataset in NPZ format. The keys in the dictionary for the weight matrices and bias vectors of linear layers are <code>W1, W2, &#8230;&#8203;</code> and <code>b1, b2, &#8230;&#8203;</code>. The keys for the training data plus targets are <code>Xtrain</code> and <code>Ttrain</code>, while for the test data plus targets we use <code>Xtest</code> and <code>Ttest</code>.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_extending_the_library">Extending the library</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The <em>Nerva-Rowwise Python Library</em> can be extended in several obvious ways, such as adding new layers, activation functions, loss functions, learning rate schedulers, and pruning or growing functions. However, the implementation of those extensions must be done in C&#43;&#43;, as documented in the section
<a href="nerva-cpp.adoc#extending">Extending the library</a> of the C&#43;&#43; manual.
After adding these components to C&#43;&#43;, they can be integrated in the <code>nerva</code> Python module.</p>
</div>
<div class="sect2">
<h3 id="_adding_a_loss_function">Adding a loss function</h3>
<div class="paragraph">
<p>As an example, we will explain how the loss function <code>SoftmaxCrossEntropyLoss</code> is added to the <code>nerva</code> Python module.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The first step is to define a C++ class <code>softmax_cross_entropy_loss</code> in the header file
<code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/include/nerva/neural_networks/loss_functions.h">loss_functions.h</a></code>.</p>
</li>
<li>
<p>The next step is to add the class <code>softmax_cross_entropy_loss</code> to the Python bindings in the file <code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/src/python-bindings.cpp">python-bindings.cpp</a></code>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre>  py::class_&lt;softmax_cross_entropy_loss, loss_function, std::shared_ptr&lt;softmax_cross_entropy_loss&gt;&gt;(m, "softmax_cross_entropy_loss")
    .def(py::init&lt;&gt;(), py::return_value_policy::copy)
    ;</pre>
</div>
</div>
<div class="ulist">
<ul>
<li>
<p>The third step is to define a Python class <code>SoftmaxCrossEntropyLoss</code> in the file <code><a href="https://github.com/wiegerw/nerva-rowwise/blob/main/python/nerva/loss-functions.py">loss-functions.py</a></code>:</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre>Unresolved directive in nerva-python.adoc - include::../python/nerva/loss_functions.py[tag=softmax_cross_entropy_loss]</pre>
</div>
</div>
<div class="paragraph">
<p>Note that the Python class derives from the C++ class. In the same file, an entry to the function <code>parse_loss_function</code> should be added.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>The last step is to reinstall the <code>nerva</code> Python module via <code>pip</code>, see <a href="#pip-install">[pip-install]</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2024-10-07 14:34:46 UTC
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains("stemblock")) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>